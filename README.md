# ðŸŒ¾ Farming Environment with Q-Learning Agent

This project demonstrates how a reinforcement learning agent (using **Q-learning**) can be trained to make intelligent farming decisions such as **planting**, **watering**, and **harvesting crops** in a grid-based farming environment.

---

## ðŸ§  Problem Statement

Traditional farming involves many manual decisions like when and where to plant, water, or harvest. These decisions are often inefficient, leading to wasted resources and reduced productivity. This project explores how **AI can automate and optimize farming operations** using reinforcement learning.

---

## ðŸ’¡ Proposed Solution

I built a custom grid-based **farming environment** where:
- Each cell can be in one of three states: `empty`, `planted`, or `ready`.
- An agent interacts with this environment using the actions: `'plant'`, `'water'`, and `'harvest'`.
- The agent is trained using **tabular Q-learning** to learn optimal farming strategies over time.

---

## ðŸ”§ Technologies Used

- **Python 3.x**
- **NumPy** â€“ for Q-table and math operations
- **Matplotlib** â€“ to visualize training performance
- **Random** â€“ for stochastic action selection

---

## ðŸ“Š Q-Learning Algorithm

Q-learning is used to estimate the optimal action-value function:

![image](https://github.com/user-attachments/assets/af9b9a30-02db-42ed-bc4b-8fc12e7199a1)

- **Î± (alpha):** Learning rate
- **Î³ (gamma):** Discount factor
- **Îµ (epsilon):** Exploration rate (used in Îµ-greedy strategy)

---

## ðŸšœ Farming Environment

- The farm is modeled as a `grid_size Ã— grid_size` matrix (default 5Ã—5).
- Actions are:
  - `plant` â†’ if cell is `empty` and agent has money
  - `water` â†’ if cell is `planted`, it becomes `ready`
  - `harvest` â†’ if cell is `ready`, earn profit and reset cell to `empty`
- Rewards are given based on correct or incorrect actions.
- State is represented as a flattened grid + current money.

---

## ðŸ“ˆ Training & Results

- The agent is trained for multiple episodes (e.g., 100).
- Performance improves over time as seen in the increasing total rewards per episode.

- ![image](https://github.com/user-attachments/assets/98b7959f-09c4-4aec-8745-814d662c471e)



